{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 2D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     38\u001b[0m generator \u001b[38;5;241m=\u001b[39m Generator()\n\u001b[1;32m---> 40\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Documents\\IRCAM\\ML\\Projet\\audio-neural-dissection\\venv\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:416\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 4D input (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: expected 4D input (got 2D input)"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Linear(100, 7 * 7 * 256, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(256, 128, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        x = x.view(-1, 7, 7, 256)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "out = generator(torch.randn(1, 100))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.leaky_relu1 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.leaky_relu2 = nn.LeakyReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(7 * 7 * 128, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss and optimizers\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.4254983365535736, 0.8891637325286865\n",
      "Epoch 1: -0.14464974403381348, 1.4986387491226196\n",
      "Epoch 1: -1.1225173473358154, 3.035031795501709\n",
      "Epoch 1: -2.6546897888183594, 6.061061859130859\n",
      "Epoch 1: -5.1285247802734375, 10.861201286315918\n",
      "Epoch 1: -8.763349533081055, 18.291431427001953\n",
      "Epoch 1: -13.697341918945312, 28.242097854614258\n",
      "Epoch 1: -19.999195098876953, 41.21295928955078\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Train the model for 10 epochs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     train(epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Save the generator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m torch\u001b[39m.\u001b[39msave(generator\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39m../models/mnist-gan-generator.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Calculate the gradients for the discriminator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m discriminator\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m d_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m optimizer_d\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Sample noise and\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pharox/Documents/ATIAM/audio-neural-dissection/code/notebooks/dc-gan-mnist.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Generate more fake images\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ATIAM/audio-neural-dissection/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ATIAM/audio-neural-dissection/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the training loop\n",
    "def train(epoch):\n",
    "    for i, (images, _) in enumerate(trainloader):\n",
    "        noise = torch.randn(64, 100)\n",
    "\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        concatenated_images = torch.cat([ images, fake_images ], 0)\n",
    "\n",
    "        predictions = discriminator(concatenated_images)\n",
    "\n",
    "        labels = torch.cat([\n",
    "            +1 * torch.ones( len(images),      1 ), \n",
    "            -1 * torch.ones( len(fake_images), 1 )\n",
    "        ])\n",
    "        d_loss = criterion(predictions, labels)\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        noise = torch.randn(64, 100)\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        predictions = discriminator(fake_images.detach())\n",
    "\n",
    "        g_loss = criterion(predictions, torch.ones(len(fake_images), 1))\n",
    "\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Print progress\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch + 1}: {d_loss.item()}, {g_loss.item()}\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "\n",
    "torch.save(generator.state_dict(), \"../models/mnist-gan-generator.pt\")\n",
    "torch.save(discriminator.state_dict(), \"../models/mnist-gan-discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = torch.randn(1, 100)\n",
    "fake_image = generator(noise)\n",
    "\n",
    "predictions = discriminator(fake_image)\n",
    "plt.imshow(fake_image[0, 0].detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
